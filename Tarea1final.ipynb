{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBz4FcYXEEao",
        "outputId": "d3406305-2582-4e7d-c453-537fc214ce6c"
      },
      "outputs": [],
      "source": [
        "!pip install datasketch \n",
        "!pip install kshingle \n",
        "!pip install pandas \n",
        "!pip install demoji\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynM10f42JSCD",
        "outputId": "de89a410-9082-4097-e57d-f99a96aae3e3"
      },
      "outputs": [],
      "source": [
        "from datasketch import MinHash, MinHashLSH\n",
        "import kshingle as ks\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import demoji\n",
        "demoji.download_codes()\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "E39W6AMJJmAf",
        "outputId": "954471c7-ef23-49b7-e97e-422d42f03433"
      },
      "outputs": [],
      "source": [
        "df_tweets = pd.read_csv('tweets_2022_abril_junio.csv')\n",
        "df_tweets.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khen5y-f07cf",
        "outputId": "529016c6-48c1-4d2a-b797-0fdab85a814f"
      },
      "outputs": [],
      "source": [
        "df_tweets = df_tweets.drop_duplicates(subset='id')\n",
        "df_tweets.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgxKdN1WJ4Ax",
        "outputId": "c1618d8d-b4cf-4822-9d8b-a685bd38727a"
      },
      "outputs": [],
      "source": [
        "df_tweets = df_tweets[df_tweets['text'].apply(lambda x: \"RT @\" not in x)].reset_index(drop=True)\n",
        "df_tweets.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIlBhjiMCEuR"
      },
      "outputs": [],
      "source": [
        "stopwords_es = set(stopwords.words('spanish'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaiNTaXvDFtZ"
      },
      "outputs": [],
      "source": [
        "def remove_emojis(texto):\n",
        "    # Expresión regular para eliminar emojis\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emoticonos\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # símbolos y pictogramas\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transporte y símbolos de mapa\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # banderas de países\n",
        "                               u\"\\U00002500-\\U00002BEF\"  # caracteres chinos, japoneses y coreanos (CJK)\n",
        "                               u\"\\U00002702-\\U000027B0\"  # símbolos de negocio\n",
        "                               u\"\\U00002702-\\U000027B0\"  # flechas y símbolos diversos\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    \n",
        "    # Eliminar emojis\n",
        "    texto_without_emojis = emoji_pattern.sub(r'', texto)\n",
        "    \n",
        "    # Preservar letras con tildes, la letra \"ñ\" y símbolos específicos\n",
        "    texto_final = re.sub(r'[^a-zA-Zá-úÁ-ÚñÑ@/: ,.;-_]+', '', texto_without_emojis)\n",
        "    \n",
        "    return texto_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqcP9iffDHkh"
      },
      "outputs": [],
      "source": [
        "def eliminar_stopwords_efficient(texto):\n",
        "    tokens = word_tokenize(texto, language='spanish')\n",
        "    texto_sin_stopwords = ' '.join([palabra for palabra in tokens if palabra.lower() not in stopwords_es]).lower()\n",
        "    texto_sin_emojis_y_stopwords = remove_emojis(texto_sin_stopwords)\n",
        "    return texto_sin_emojis_y_stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "920e7Kk_DIvp"
      },
      "outputs": [],
      "source": [
        "df_tweets['text'] = df_tweets['text'].apply(eliminar_stopwords_efficient)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HIqN4tf12a_Q",
        "outputId": "77f2ad55-dc70-420a-a7fd-977929f2a22f"
      },
      "outputs": [],
      "source": [
        "# Se eliminan los text que no tienen texto\n",
        "df_tweets = df_tweets.dropna(subset=['text'])\n",
        "df_tweets.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1oUljTI-DJ92",
        "outputId": "36b1fcda-3da0-44cc-852a-26f123234aa2"
      },
      "outputs": [],
      "source": [
        "# Crear el shingle de cada tweet\n",
        "df_tweets['shingles'] = df_tweets['text'].apply(lambda x: ks.shingleset_list(x, [4]))\n",
        "df_tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FlqxG6hNDRjn"
      },
      "outputs": [],
      "source": [
        "# Crear un diccionario con key = id y value = shingles\n",
        "dict_shingles = {}\n",
        "for i in df_tweets.index:\n",
        "    id_tweet = df_tweets[\"id\"][i]\n",
        "    shingles = df_tweets[\"shingles\"][i]\n",
        "    dict_shingles[id_tweet] = shingles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk2W-1CZDTWP",
        "outputId": "1874164b-117b-4f55-858e-c9dba627bec6"
      },
      "outputs": [],
      "source": [
        "# Se crea una lista de los usuarios\n",
        "ids_tweet = list(dict_shingles.keys())\n",
        "len(ids_tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdWpkDslDUYD"
      },
      "outputs": [],
      "source": [
        "dict_minhash = {}\n",
        "for id_tweet in ids_tweet:\n",
        "    shingles = dict_shingles[id_tweet]\n",
        "    m = MinHash(num_perm=128)\n",
        "    for d in shingles:\n",
        "        m.update(d.encode('utf8'))\n",
        "    dict_minhash[id_tweet] = m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCjqql3lDVhs"
      },
      "outputs": [],
      "source": [
        "# Ahora vemos el MinHashLSH\n",
        "lsh = MinHashLSH(threshold=0.6, num_perm=128)\n",
        "for id_tweet in ids_tweet:\n",
        "    lsh.insert(id_tweet, dict_minhash[id_tweet])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHkqVfXl1fMK"
      },
      "outputs": [],
      "source": [
        "# Se crea una función para buscar los tweets similares\n",
        "def buscar_tweets_similares(id_tweet, df_tweets, lsh, dict_minhash):\n",
        "    # Se obtiene el MinHash del tweet\n",
        "    m = dict_minhash[id_tweet]\n",
        "    \n",
        "    # Se obtienen los ids de los tweets similares\n",
        "    ids_similares = lsh.query(m)\n",
        "    \n",
        "    # Se obtienen los tweets similares\n",
        "    tweets_similares = df_tweets.loc[ids_similares]\n",
        "    \n",
        "    return tweets_similares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "914iUxUm2NUh"
      },
      "outputs": [],
      "source": [
        "df_tweets_indexado = df_tweets.set_index('id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1fDVa161g8l"
      },
      "outputs": [],
      "source": [
        "# Buscaremos quien escribe similar a un usuario en específico, para esto filtramos el dataframe por el usuario\n",
        "user_name = 'MacaSimplemente'\n",
        "df_user = df_tweets_indexado[df_tweets_indexado['screen_name'] == user_name]\n",
        "df_user.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWR-mcRK1iyd"
      },
      "outputs": [],
      "source": [
        "# iteramos sobre los tweets del usuario y buscamos los tweets similares, para esto usamos la función buscar_tweets_similares, guardamos las repeticiones en un diccionario de los usuarios similares, para saber quien es el usuario que más se repite\n",
        "dict_similares = {}\n",
        "for id_tweet in df_user.index:\n",
        "    tweets_similares = buscar_tweets_similares(id_tweet, df_tweets_indexado, lsh, dict_minhash)\n",
        "    for id_similar in tweets_similares.index:\n",
        "        if id_similar != id_tweet:\n",
        "            screen_name = tweets_similares['screen_name'][id_similar]\n",
        "            if screen_name in dict_similares:\n",
        "                dict_similares[screen_name] += 1\n",
        "            else:\n",
        "                dict_similares[screen_name] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZAV01Sy1kVQ"
      },
      "outputs": [],
      "source": [
        "# Obtener los 3 usuarios más similares\n",
        "sorted(dict_similares.items(), key=lambda x: x[1], reverse=True)[:3]\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
